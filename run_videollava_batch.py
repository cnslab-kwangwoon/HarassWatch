import os
import torch
import numpy as np
import av
import pandas as pd
from tqdm import tqdm
from transformers import VideoLlavaProcessor, VideoLlavaForConditionalGeneration

# ì„¤ì •
CSV_PATH = "social_vr_eval_list.csv"
OUTPUT_PATH = "social_vr_eval_results_wo_background.csv"
# REASON_PATH = "social_vr_eval_reasons_wo_background.csv"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_ID = "LanguageBind/Video-LLaVA-7B-hf"
with open("PROMPT_v2.txt", "r", encoding="utf-8") as f:
    PROMPT_TEMPLATE = f.read().strip()

# ëª¨ë¸ ë¡œë“œ
print("ğŸ”§ Loading Video-LLaVA...")
processor = VideoLlavaProcessor.from_pretrained(MODEL_ID)
model = VideoLlavaForConditionalGeneration.from_pretrained(
    MODEL_ID,
    torch_dtype=torch.float16 if DEVICE.type == "cuda" else torch.float32
).to(DEVICE)
print("âœ… Model loaded.")

# í”„ë ˆì„ ì¶”ì¶œ í•¨ìˆ˜
def extract_frames(video_path, num_frames=8):
    container = av.open(video_path)
    stream = container.streams.video[0]
    total_frames = stream.frames
    if total_frames == 0:
        raise ValueError("No frames in video.")
    indices = np.linspace(0, total_frames - 1, num=num_frames, dtype=int)

    frames = []
    for i, frame in enumerate(container.decode(video=0)):
        if i in indices:
            frames.append(frame.to_ndarray(format="rgb24"))
        if i > indices[-1]:
            break
    return np.stack(frames)

# ì¶”ë¡ 
df = pd.read_csv(CSV_PATH)
results = []
reasons = []

for idx, row in tqdm(df.iterrows(), total=len(df)):
    video_path = row["video_path"]
    true_label = row["label"]
    full_path = os.path.join(".", video_path)

    print(f"\nâ–¶ï¸ [{idx + 1}/{len(df)}] Processing: {video_path}")

    try:
        frames = extract_frames(full_path)
        print("âœ… Frame extraction successful.")

        prompt = f"USER: <video> {PROMPT_TEMPLATE} ASSISTANT:"
        inputs = processor(text=prompt, videos=frames, return_tensors="pt")
        inputs = {k: v.to(DEVICE) for k, v in inputs.items()}

        with torch.no_grad():
            output_ids = model.generate(**inputs, max_new_tokens=512)

        answer_raw = processor.batch_decode(output_ids, skip_special_tokens=True)[0]
        print(f"ğŸ—¨ï¸ Raw response: {answer_raw}")

        # ASSISTANT: íƒœê·¸ ì´í›„ë§Œ ì‚¬ìš©
        if "ASSISTANT:" in answer_raw:
            answer = answer_raw.split("ASSISTANT:")[-1].strip()
        else:
            answer = answer_raw.strip()

        # ë¶„ë¥˜ íŒë‹¨
        lower = answer.lower()
        if "aggressive behavior" in lower:
            pred = "Aggressive"
        elif "personal space violation" in lower:
            pred = "Personal"
        else:
            pred = "Benign"

        # ì´ìœ  ë¶„ë¦¬
        first_period = answer.find(".")
        reasoning = answer[first_period+1:].strip() if first_period != -1 else ""

        print(f"ğŸ“Œ Predicted: {pred}")
        print(f"ğŸ§  Reason: {reasoning}")

        # âœ… ì¤‘ê°„ ì €ì¥
        if (idx + 1) % 10 == 0:
            pd.DataFrame(results).to_csv(OUTPUT_PATH, index=False)
            print(f"ğŸ’¾ [{idx + 1}] Interim results saved to CSV.")

    except Exception as e:
        answer = f"[ERROR] {e}"
        pred = "Error"
        reasoning = f"[ERROR] {e}"
        print(f"âŒ Error processing video: {e}")

    results.append({
        "video_path": video_path,
        "true_label": true_label,
        "predicted_label": pred,
        "response_text": answer.strip()
    })

    # reasons.append({
    #     "video_path": video_path,
    #     "reason": reasoning.strip()
    # })

# ê²°ê³¼ ì €ì¥
pd.DataFrame(results).to_csv(OUTPUT_PATH, index=False)
print(f"\nâœ… ì €ì¥ ì™„ë£Œ: {OUTPUT_PATH}")

# pd.DataFrame(reasons).to_csv(REASON_PATH, index=False)
# print(f"\nâœ… ì €ì¥ ì™„ë£Œ: {OUTPUT_PATH}, {REASON_PATH}")